# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GIqnLDwQ5aP_v78JSGuL2LfyPDvNXdBO
"""

import torch

if torch.cuda.is_available():
    print(f"GPU is available: {torch.cuda.get_device_name(0)}")
else:
    print("GPU not available, running on CPU.")

import pandas as pd
import numpy as np
import time
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import precision_score, recall_score, log_loss, classification_report

# 3. Load Dataset
df = pd.read_csv('Micro-credit-Data-file.csv')  # Update path if needed

# 4. Preprocessing
df.dropna(inplace=True)  # Drop rows with missing values

# Convert categorical features using LabelEncoder or pd.get_dummies
cat_cols = df.select_dtypes(include='object').columns
for col in cat_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])

# Set features and target
X = df.drop('label', axis=1)  # Update if your target column has a different name
y = df['label']

# 5. Train-Test Split and Scaling
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

from sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier, PassiveAggressiveClassifier, Perceptron
from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier, NearestCentroid, RadiusNeighborsClassifier
from sklearn.dummy import DummyClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier

models = [
    LogisticRegression(penalty='l2', solver='lbfgs', max_iter=300),
    LogisticRegression(penalty='none', solver='lbfgs', max_iter=300),
    LogisticRegression(penalty='l2', solver='saga', max_iter=300),
    SGDClassifier(loss="log_loss", max_iter=300, tol=1e-3),
    SGDClassifier(loss="hinge", max_iter=300, tol=1e-3),
    SGDClassifier(loss="modified_huber", max_iter=300, tol=1e-3),
    RidgeClassifier(),
    PassiveAggressiveClassifier(max_iter=300),
    Perceptron(max_iter=300),
    LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=300),

    GaussianNB(),
    MultinomialNB(),
    ComplementNB(),
    BernoulliNB(),

    DecisionTreeClassifier(max_depth=3),
    DecisionTreeClassifier(max_depth=5),
    DecisionTreeClassifier(max_depth=7),
    RandomForestClassifier(n_estimators=10, max_depth=5),
    RandomForestClassifier(n_estimators=20, max_depth=5),
    ExtraTreesClassifier(n_estimators=10, max_depth=5),
    ExtraTreesClassifier(n_estimators=20, max_depth=5),
    BaggingClassifier(estimator=DecisionTreeClassifier(max_depth=3), n_estimators=10),
    BaggingClassifier(estimator=LogisticRegression(max_iter=300), n_estimators=10),


    KNeighborsClassifier(n_neighbors=3),
    KNeighborsClassifier(n_neighbors=5),
    KNeighborsClassifier(n_neighbors=7),
    NearestCentroid(),
    RadiusNeighborsClassifier(radius=1.0),

    GradientBoostingClassifier(n_estimators=20, max_depth=3),
    GradientBoostingClassifier(n_estimators=30, max_depth=3),
    HistGradientBoostingClassifier(max_iter=20),
    HistGradientBoostingClassifier(max_iter=30),
    XGBClassifier(n_estimators=20, use_label_encoder=False, eval_metric='logloss', verbosity=0),
    LGBMClassifier(n_estimators=20),

    DummyClassifier(strategy='most_frequent'),
    DummyClassifier(strategy='stratified'),
    DummyClassifier(strategy='uniform'),
    DummyClassifier(strategy='constant', constant=1),
    DummyClassifier(strategy='constant', constant=0)
]

results = []

for i, model in enumerate(models, 1):
    model_name = type(model).__name__
    try:
        start = time.time()
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_test_scaled)
        y_prob = model.predict_proba(X_test_scaled) if hasattr(model, "predict_proba") else None
        end = time.time()

        precision = precision_score(y_test, y_pred)
        recall = recall_score(y_test, y_pred)
        logloss = log_loss(y_test, y_prob) if y_prob is not None else np.nan
        elapsed = end - start

        results.append({
            'Model': model_name,
            'Precision': precision,
            'Recall': recall,
            'Log Loss': logloss,
            'Time (s)': elapsed
        })

        print(f"{i:02d}. {model_name} ✔️ — Time: {elapsed:.2f}s")

    except Exception as e:
        print(f"{i:02d}. {model_name} ❌ Failed: {e}")
        results.append({
            'Model': model_name,
            'Precision': np.nan,
            'Recall': np.nan,
            'Log Loss': np.nan,
            'Time (s)': np.nan
        })

results_df = pd.DataFrame(results)
results_df = results_df.sort_values(by='Log Loss', ascending=True).reset_index(drop=True)
results_df.style.background_gradient(cmap='Blues')

results_df.to_csv('model_comparison_results.csv', index=False)

from sklearn.naive_bayes import MultinomialNB, ComplementNB
from sklearn.preprocessing import MinMaxScaler

# Prepare data for Naive Bayes
minmax_scaler = MinMaxScaler()
X_train_nb = minmax_scaler.fit_transform(X_train)
X_test_nb = minmax_scaler.transform(X_test)

# Define models
nb_models = [
    ('MultinomialNB', MultinomialNB()),
    ('ComplementNB', ComplementNB())
]

# Evaluate them
for name, model in nb_models:
    try:
        start = time.time()
        model.fit(X_train_nb, y_train)
        y_pred = model.predict(X_test_nb)
        y_prob = model.predict_proba(X_test_nb)
        end = time.time()

        precision = precision_score(y_test, y_pred)
        recall = recall_score(y_test, y_pred)
        logloss = log_loss(y_test, y_prob)
        elapsed = end - start

        results_df.loc[len(results_df)] = [name, precision, recall, logloss, elapsed]
        print(f"{name} ✔️ Reprocessed — Time: {elapsed:.2f}s")

    except Exception as e:
        print(f"{name} ❌ Error after fix: {e}")

from sklearn.neighbors import RadiusNeighborsClassifier

try:
    model_name = 'RadiusNeighborsClassifier'
    start = time.time()
    radius_model = RadiusNeighborsClassifier(radius=10.0)
    radius_model.fit(X_train_scaled, y_train)
    y_pred = radius_model.predict(X_test_scaled)
    y_prob = radius_model.predict_proba(X_test_scaled)
    end = time.time()

    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    logloss = log_loss(y_test, y_prob)
    elapsed = end - start

    results_df.loc[len(results_df)] = [model_name, precision, recall, logloss, elapsed]
    print(f"{model_name} ✔️ Reprocessed — Time: {elapsed:.2f}s")

except Exception as e:
    print(f"{model_name} ❌ Error after fix: {e}")

results_df = pd.DataFrame(results)
results_df = results_df.sort_values(by='Log Loss', ascending=True).reset_index(drop=True)
results_df.style.background_gradient(cmap='Blues')

import joblib

# Replace with your actual trained model variable
final_model = XGBClassifier()
final_model.fit(X_train, y_train)

# Save the trained model
joblib.dump(final_model, 'final_model.pkl')

# If you used a scaler
joblib.dump(scaler, 'scaler.pkl')

import pandas as pd

results_df = pd.read_csv('model_comparison_results.csv')

# Example: Select model with highest recall
best_model = results_df.loc[results_df['Recall'].idxmax()]

print("Best model based on Recall:")
print(best_model)

import pandas as pd

# Load the CSV file containing model evaluation metrics
results_df = pd.read_csv('model_comparison_results.csv')

# Drop rows where Precision is NaN (if any)
results_df = results_df.dropna(subset=['Precision'])

# Find the row with the highest Precision
best_model_row = results_df.loc[results_df['Precision'].idxmax()]

print("Best model based on Precision:")
print(best_model_row)

import pandas as pd
from sklearn.preprocessing import MinMaxScaler

# Load your results CSV
results_df = pd.read_csv('model_comparison_results.csv')

# Drop rows with NaN in critical columns
results_df = results_df.dropna(subset=['Precision', 'Recall', ])

# Min-max scale Precision, Recall, and LogLoss (LogLoss is to be minimized, so invert it)
scaler = MinMaxScaler()

# Scale Precision and Recall normally
results_df[['Precision_scaled', 'Recall_scaled']] = scaler.fit_transform(results_df[['Precision', 'Recall']])



# Define weights (you can adjust these as per your priority)
w_precision = 0.4
w_recall = 0.4


# Calculate combined score
results_df['Combined_Score'] = (
    w_precision * results_df['Precision_scaled'] +
    w_recall * results_df['Recall_scaled']

)

# Select the best model
best_model_row = results_df.loc[results_df['Combined_Score'].idxmax()]

print("Best model balancing Precision, Recall, and Log Loss:")
print(best_model_row)

# Get model name
best_model_name = best_model_row['Model']  # Adjust if your column name is different
print(f"Selected model: {best_model_name}")

import pandas as pd
from sklearn.preprocessing import MinMaxScaler

# Load your CSV results
results_df = pd.read_csv('model_comparison_results.csv')

# Drop rows with NaN in critical columns
results_df = results_df.dropna(subset=['Precision', 'Recall', 'Time'])

# Min-max scale Precision and Recall normally
scaler = MinMaxScaler()
results_df[['Precision_scaled', 'Recall_scaled']] = scaler.fit_transform(results_df[['Precision', 'Recall']])

# Scale time and invert because lower time is better
time_scaled = scaler.fit_transform(results_df[['Time']])
results_df['Time_scaled'] = 1 - time_scaled  # invert to make higher better

# Weights for each metric - adjust if needed
w_precision = 0.4
w_recall = 0.4
w_time = 0.2

# Combined score calculation
results_df['Combined_Score'] = (
    w_precision * results_df['Precision_scaled'] +
    w_recall * results_df['Recall_scaled'] +
    w_time * results_df['Time_scaled']
)

# Find best model based on combined score
best_model_row = results_df.loc[results_df['Combined_Score'].idxmax()]

print("Best model balancing Precision, Recall, and Execution Time:")
print(best_model_row)

# Model name
best_model_name = best_model_row['Model']
print(f"Selected model: {best_model_name}")

import pandas as pd

# Replace 'results.csv' with your actual file path
df = pd.read_csv('model_comparison_results.csv')

print(df.head())

df_sorted = df.sort_values(by=['Precision', 'Recall', 'PredictionTime'], ascending=[False, False, True])

import pandas as pd

# Load the CSV file (replace 'results.csv' with your actual file path)
df = pd.read_csv('model_comparison_results.csv')

# Display first few rows to verify
print(df.head())

# Sort by Precision (desc), Recall (desc), and Time (asc)
df_sorted = df.sort_values(by=['Precision', 'Recall', 'Time (s)'], ascending=[False, False, True])

# Get the best model row
best_model_row = df_sorted.iloc[0]
print("Best model based on Precision, Recall and Time:")
print(best_model_row)

# Extract best model name
best_model_name = best_model_row['Model']

print(f"Selected model: {best_model_name}")

import joblib

model_filename = f"{best_model_name}.pkl"
best_model = joblib.load(model_filename)

import joblib

model_filename = f"{best_model_name}.pkl"
best_model = joblib.load(model_filename)

import joblib
from sklearn.naive_bayes import GaussianNB

model = GaussianNB()
model.fit(X_train, y_train)

# Save the model
joblib.dump(model, 'GaussianNB.pkl')
print("Model saved as GaussianNB.pkl")

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
import joblib

# Example: Load your dataset CSV again
data = pd.read_csv('Micro-credit-Data-file.csv')

# Replace 'features' and 'target' with your actual columns
X = data.drop('target_column', axis=1)
y = data['target_column']

# Split into train and test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train model
model = GaussianNB()
model.fit(X_train, y_train)

# Save model
joblib.dump(model, 'GaussianNB.pkl')
print("Model saved!")

from sklearn.naive_bayes import GaussianNB
import joblib

# Assuming your earlier code has run and you have these:
# X_train_scaled, y_train, X_test_scaled, y_test

model = GaussianNB()
model.fit(X_train_scaled, y_train)

# Save the model for later use
joblib.dump(model, 'GaussianNB.pkl')

# Predict and evaluate
y_pred = model.predict(X_test_scaled)
print(classification_report(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred))
print("Recall:", recall_score(y_test, y_pred))

# If you want to load the model later:
# loaded_model = joblib.load('GaussianNB.pkl')

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder

# Load Dataset
df = pd.read_csv('Micro-credit-Data-file.csv')  # Adjust path if needed

# Preprocessing
df.dropna(inplace=True)

# Convert categorical columns
cat_cols = df.select_dtypes(include='object').columns
for col in cat_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])

# Features and target
X = df.drop('label', axis=1)
y = df['label']

# Train-test split and scaling
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

from sklearn.naive_bayes import GaussianNB
import joblib

model = GaussianNB()
model.fit(X_train_scaled, y_train)

joblib.dump(model, 'GaussianNB.pkl')

y_pred = model.predict(X_test_scaled)
print(classification_report(y_test, y_pred))

from sklearn.metrics import classification_report

from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import classification_report
import joblib

model = GaussianNB()
model.fit(X_train_scaled, y_train)

joblib.dump(model, 'GaussianNB.pkl')

y_pred = model.predict(X_test_scaled)
print(classification_report(y_test, y_pred))

from xgboost import XGBClassifier
from sklearn.metrics import classification_report, precision_score, recall_score, log_loss
import joblib

# Initialize model
model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)

# Fit model on scaled training data
model.fit(X_train_scaled, y_train)

# Predict on test data
y_pred = model.predict(X_test_scaled)

# Predict probabilities for log loss
y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]

# Print classification report
print("XGBClassifier Results:")
print(classification_report(y_test, y_pred))

# Print precision, recall, log loss
print("Precision:", precision_score(y_test, y_pred))
print("Recall:", recall_score(y_test, y_pred))
print("Log Loss:", log_loss(y_test, y_pred_proba))

# Save the model
joblib.dump(model, 'XGBClassifier.pkl')
print("Model saved as XGBClassifier.pkl")

from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis
from sklearn.calibration import CalibratedClassifierCV
from sklearn.linear_model import RidgeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.dummy import DummyClassifier
from sklearn.metrics import precision_score, recall_score, log_loss
import time

results = []

# QDA
start = time.time()
qda = QuadraticDiscriminantAnalysis()
qda.fit(X_train_scaled, y_train)
y_pred = qda.predict(X_test_scaled)
y_prob = qda.predict_proba(X_test_scaled)
results.append({
    "Model": "QuadraticDiscriminantAnalysis",
    "Precision": precision_score(y_test, y_pred),
    "Recall": recall_score(y_test, y_pred),
    "Log Loss": log_loss(y_test, y_prob),
    "Time (s)": time.time() - start
})

# LDA
start = time.time()
lda = LinearDiscriminantAnalysis()
lda.fit(X_train_scaled, y_train)
y_pred = lda.predict(X_test_scaled)
y_prob = lda.predict_proba(X_test_scaled)
results.append({
    "Model": "LinearDiscriminantAnalysis",
    "Precision": precision_score(y_test, y_pred),
    "Recall": recall_score(y_test, y_pred),
    "Log Loss": log_loss(y_test, y_prob),
    "Time (s)": time.time() - start
})

# DummyClassifier (stratified)
start = time.time()
dummy = DummyClassifier(strategy="stratified")
dummy.fit(X_train_scaled, y_train)
y_pred = dummy.predict(X_test_scaled)
y_prob = dummy.predict_proba(X_test_scaled)
results.append({
    "Model": "DummyClassifier-stratified",
    "Precision": precision_score(y_test, y_pred),
    "Recall": recall_score(y_test, y_pred),
    "Log Loss": log_loss(y_test, y_prob),
    "Time (s)": time.time() - start
})

# Calibrated Classifier (with RidgeClassifier)
start = time.time()
ridge = RidgeClassifier()
calib = CalibratedClassifierCV(ridge)
calib.fit(X_train_scaled, y_train)
y_pred = calib.predict(X_test_scaled)
y_prob = calib.predict_proba(X_test_scaled)
results.append({
    "Model": "Calibrated-RidgeClassifier",
    "Precision": precision_score(y_test, y_pred),
    "Recall": recall_score(y_test, y_pred),
    "Log Loss": log_loss(y_test, y_prob),
    "Time (s)": time.time() - start
})

# GaussianNB (Binarized)
from sklearn.preprocessing import Binarizer
start = time.time()
binarizer = Binarizer().fit(X_train_scaled)
X_train_bin = binarizer.transform(X_train_scaled)
X_test_bin = binarizer.transform(X_test_scaled)
gnb = GaussianNB()
gnb.fit(X_train_bin, y_train)
y_pred = gnb.predict(X_test_bin)
y_prob = gnb.predict_proba(X_test_bin)
results.append({
    "Model": "GaussianNB-Binarized",
    "Precision": precision_score(y_test, y_pred),
    "Recall": recall_score(y_test, y_pred),
    "Log Loss": log_loss(y_test, y_prob),
    "Time (s)": time.time() - start
})

# Create DataFrame of new results
import pandas as pd
new_models_df = pd.DataFrame(results)
print(new_models_df)

final_df = pd.concat([existing_df, new_models_df], ignore_index=True)
final_df.to_csv('updated_models_metrics.csv', index=False)

import pandas as pd

# Load the existing model results CSV
existing_df = pd.read_csv('model_comparison_results.csv')  # Replace with your actual filename if different

# Now concatenate with the new models
final_df = pd.concat([existing_df, new_models_df], ignore_index=True)

# Save the updated list of models
final_df.to_csv('updated_models_metrics.csv', index=False)

print("✅ Model list updated and saved as 'updated_models_metrics.csv'")

from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.metrics import precision_score, recall_score, log_loss, classification_report
import time

# Start timing
start = time.time()

# Initialize and train the model
qda_model = QuadraticDiscriminantAnalysis()
qda_model.fit(X_train_scaled, y_train)

# Predict
y_pred = qda_model.predict(X_test_scaled)
y_proba = qda_model.predict_proba(X_test_scaled)

# Evaluate
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
loss = log_loss(y_test, y_proba)
duration = time.time() - start

print("QDA Results:")
print(classification_report(y_test, y_pred))
print("Precision:", precision)
print("Recall:", recall)
print("Log Loss:", loss)
print("Time Taken:", duration)

# Add to DataFrame if you're collecting model results
new_model_result = pd.DataFrame([{
    'Model': 'QuadraticDiscriminantAnalysis',
    'Precision': precision,
    'Recall': recall,
    'Log Loss': loss,
    'Time (s)': duration
}])

# If you already have a DataFrame of results (like existing_df or final_df):
# final_df = pd.concat([final_df, new_model_result], ignore_index=True)

import pandas as pd

# Load existing results CSV
final_df = pd.read_csv('updated_models_metrics.csv')  # Adjust the filename if different

# Replace these with actual values from your QDA model run
qda_result = pd.DataFrame([{
    'Model': 'QuadraticDiscriminantAnalysis',
    'Precision': precision,  # from your QDA evaluation
    'Recall': recall,
    'Log Loss': loss,
    'Time (s)': duration
}])

# Concatenate and save
final_df = pd.concat([final_df, qda_result], ignore_index=True)
final_df.to_csv('updated_models_metrics.csv', index=False)

print(final_df.tail())  # Shows the last few rows including the new entry


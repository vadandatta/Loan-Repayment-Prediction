{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9faGyM0sdluA",
        "outputId": "8f868058-e77b-42b6-f9eb-fe7196de784c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU is available: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"GPU not available, running on CPU.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import precision_score, recall_score, log_loss, classification_report\n",
        "\n",
        "# 3. Load Dataset\n",
        "df = pd.read_csv('Micro-credit-Data-file.csv')  # Update path if needed\n",
        "\n",
        "# 4. Preprocessing\n",
        "df.dropna(inplace=True)  # Drop rows with missing values\n",
        "\n",
        "# Convert categorical features using LabelEncoder or pd.get_dummies\n",
        "cat_cols = df.select_dtypes(include='object').columns\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Set features and target\n",
        "X = df.drop('label', axis=1)  # Update if your target column has a different name\n",
        "y = df['label']\n",
        "\n",
        "# 5. Train-Test Split and Scaling\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "9RrGViMzeIq5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier, PassiveAggressiveClassifier, Perceptron\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid, RadiusNeighborsClassifier\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "models = [\n",
        "    LogisticRegression(penalty='l2', solver='lbfgs', max_iter=300),\n",
        "    LogisticRegression(penalty='none', solver='lbfgs', max_iter=300),\n",
        "    LogisticRegression(penalty='l2', solver='saga', max_iter=300),\n",
        "    SGDClassifier(loss=\"log_loss\", max_iter=300, tol=1e-3),\n",
        "    SGDClassifier(loss=\"hinge\", max_iter=300, tol=1e-3),\n",
        "    SGDClassifier(loss=\"modified_huber\", max_iter=300, tol=1e-3),\n",
        "    RidgeClassifier(),\n",
        "    PassiveAggressiveClassifier(max_iter=300),\n",
        "    Perceptron(max_iter=300),\n",
        "    LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=300),\n",
        "\n",
        "    GaussianNB(),\n",
        "    MultinomialNB(),\n",
        "    ComplementNB(),\n",
        "    BernoulliNB(),\n",
        "\n",
        "    DecisionTreeClassifier(max_depth=3),\n",
        "    DecisionTreeClassifier(max_depth=5),\n",
        "    DecisionTreeClassifier(max_depth=7),\n",
        "    RandomForestClassifier(n_estimators=10, max_depth=5),\n",
        "    RandomForestClassifier(n_estimators=20, max_depth=5),\n",
        "    ExtraTreesClassifier(n_estimators=10, max_depth=5),\n",
        "    ExtraTreesClassifier(n_estimators=20, max_depth=5),\n",
        "    BaggingClassifier(estimator=DecisionTreeClassifier(max_depth=3), n_estimators=10),\n",
        "    BaggingClassifier(estimator=LogisticRegression(max_iter=300), n_estimators=10),\n",
        "\n",
        "\n",
        "    KNeighborsClassifier(n_neighbors=3),\n",
        "    KNeighborsClassifier(n_neighbors=5),\n",
        "    KNeighborsClassifier(n_neighbors=7),\n",
        "    NearestCentroid(),\n",
        "    RadiusNeighborsClassifier(radius=1.0),\n",
        "\n",
        "    GradientBoostingClassifier(n_estimators=20, max_depth=3),\n",
        "    GradientBoostingClassifier(n_estimators=30, max_depth=3),\n",
        "    HistGradientBoostingClassifier(max_iter=20),\n",
        "    HistGradientBoostingClassifier(max_iter=30),\n",
        "    XGBClassifier(n_estimators=20, use_label_encoder=False, eval_metric='logloss', verbosity=0),\n",
        "    LGBMClassifier(n_estimators=20),\n",
        "\n",
        "    DummyClassifier(strategy='most_frequent'),\n",
        "    DummyClassifier(strategy='stratified'),\n",
        "    DummyClassifier(strategy='uniform'),\n",
        "    DummyClassifier(strategy='constant', constant=1),\n",
        "    DummyClassifier(strategy='constant', constant=0)\n",
        "]\n"
      ],
      "metadata": {
        "id": "YVmXrH7Ke_HI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for i, model in enumerate(models, 1):\n",
        "    model_name = type(model).__name__\n",
        "    try:\n",
        "        start = time.time()\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "        y_prob = model.predict_proba(X_test_scaled) if hasattr(model, \"predict_proba\") else None\n",
        "        end = time.time()\n",
        "\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        logloss = log_loss(y_test, y_prob) if y_prob is not None else np.nan\n",
        "        elapsed = end - start\n",
        "\n",
        "        results.append({\n",
        "            'Model': model_name,\n",
        "            'Precision': precision,\n",
        "            'Recall': recall,\n",
        "            'Log Loss': logloss,\n",
        "            'Time (s)': elapsed\n",
        "        })\n",
        "\n",
        "        print(f\"{i:02d}. {model_name} ✔️ — Time: {elapsed:.2f}s\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"{i:02d}. {model_name} ❌ Failed: {e}\")\n",
        "        results.append({\n",
        "            'Model': model_name,\n",
        "            'Precision': np.nan,\n",
        "            'Recall': np.nan,\n",
        "            'Log Loss': np.nan,\n",
        "            'Time (s)': np.nan\n",
        "        })\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TIqq1CefEbU",
        "outputId": "c899d562-341b-47bb-a16e-e5f2a61ecc70"
      },
      "execution_count": 4,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "01. LogisticRegression ✔️ — Time: 3.90s\n",
            "02. LogisticRegression ❌ Failed: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'elasticnet'} or None. Got 'none' instead.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "03. LogisticRegression ✔️ — Time: 41.61s\n",
            "04. SGDClassifier ✔️ — Time: 0.73s\n",
            "05. SGDClassifier ✔️ — Time: 1.01s\n",
            "06. SGDClassifier ✔️ — Time: 2.10s\n",
            "07. RidgeClassifier ✔️ — Time: 0.12s\n",
            "08. PassiveAggressiveClassifier ✔️ — Time: 0.50s\n",
            "09. Perceptron ✔️ — Time: 0.31s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10. LogisticRegression ✔️ — Time: 48.66s\n",
            "11. GaussianNB ✔️ — Time: 0.15s\n",
            "12. MultinomialNB ❌ Failed: Negative values in data passed to MultinomialNB (input X).\n",
            "13. ComplementNB ❌ Failed: Negative values in data passed to ComplementNB (input X).\n",
            "14. BernoulliNB ✔️ — Time: 0.18s\n",
            "15. DecisionTreeClassifier ✔️ — Time: 0.95s\n",
            "16. DecisionTreeClassifier ✔️ — Time: 1.36s\n",
            "17. DecisionTreeClassifier ✔️ — Time: 1.76s\n",
            "18. RandomForestClassifier ✔️ — Time: 1.71s\n",
            "19. RandomForestClassifier ✔️ — Time: 4.29s\n",
            "20. ExtraTreesClassifier ✔️ — Time: 0.30s\n",
            "21. ExtraTreesClassifier ✔️ — Time: 0.59s\n",
            "22. BaggingClassifier ✔️ — Time: 6.23s\n",
            "23. BaggingClassifier ✔️ — Time: 39.87s\n",
            "24. KNeighborsClassifier ✔️ — Time: 88.73s\n",
            "25. KNeighborsClassifier ✔️ — Time: 87.61s\n",
            "26. KNeighborsClassifier ✔️ — Time: 86.22s\n",
            "27. NearestCentroid ✔️ — Time: 0.14s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_nearest_centroid.py:244: UserWarning: self.within_class_std_dev_ has at least 1 zero standard deviation.Inputs within the same classes for at least 1 feature are identical.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28. RadiusNeighborsClassifier ❌ Failed: No neighbors found for test samples array([    1,     7,    14, ..., 41908, 41910, 41915]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
            "29. GradientBoostingClassifier ✔️ — Time: 19.61s\n",
            "30. GradientBoostingClassifier ✔️ — Time: 28.77s\n",
            "31. HistGradientBoostingClassifier ✔️ — Time: 1.71s\n",
            "32. HistGradientBoostingClassifier ✔️ — Time: 2.78s\n",
            "33. XGBClassifier ✔️ — Time: 1.36s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 146744, number of negative: 20930\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047344 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 6152\n",
            "[LightGBM] [Info] Number of data points in the train set: 167674, number of used features: 35\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.875174 -> initscore=1.947506\n",
            "[LightGBM] [Info] Start training from score 1.947506\n",
            "34. LGBMClassifier ✔️ — Time: 1.67s\n",
            "35. DummyClassifier ✔️ — Time: 0.00s\n",
            "36. DummyClassifier ✔️ — Time: 0.00s\n",
            "37. DummyClassifier ✔️ — Time: 0.00s\n",
            "38. DummyClassifier ✔️ — Time: 0.00s\n",
            "39. DummyClassifier ✔️ — Time: 0.00s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values(by='Log Loss', ascending=True).reset_index(drop=True)\n",
        "results_df.style.background_gradient(cmap='Blues')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KdHS4eutfhPW",
        "outputId": "cb81d209-dea0-40df-cea7-df8bde390e2a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x79b14993aa90>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_073a1_row0_col1, #T_073a1_row1_col1 {\n",
              "  background-color: #083979;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_073a1_row0_col2, #T_073a1_row1_col2 {\n",
              "  background-color: #083573;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_073a1_row0_col3, #T_073a1_row1_col3, #T_073a1_row2_col3, #T_073a1_row3_col3, #T_073a1_row4_col3, #T_073a1_row5_col3, #T_073a1_row6_col3, #T_073a1_row7_col3, #T_073a1_row8_col3, #T_073a1_row9_col3, #T_073a1_row10_col3, #T_073a1_row11_col3, #T_073a1_row12_col3, #T_073a1_row13_col3, #T_073a1_row14_col3, #T_073a1_row15_col3, #T_073a1_row16_col3, #T_073a1_row18_col4, #T_073a1_row20_col4, #T_073a1_row21_col4, #T_073a1_row24_col4, #T_073a1_row26_col4, #T_073a1_row27_col4, #T_073a1_row28_col4, #T_073a1_row29_col4, #T_073a1_row30_col1, #T_073a1_row30_col2, #T_073a1_row30_col4, #T_073a1_row33_col4, #T_073a1_row35_col4 {\n",
              "  background-color: #f7fbff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_073a1_row0_col4, #T_073a1_row6_col4, #T_073a1_row19_col3 {\n",
              "  background-color: #f5f9fe;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_073a1_row1_col4 {\n",
              "  background-color: #f1f7fd;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_073a1_row2_col1, #T_073a1_row3_col1 {\n",
              "  background-color: #083a7a;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_073a1_row2_col2, #T_073a1_row3_col2, #T_073a1_row4_col2, #T_073a1_row6_col2 {\n",
              "  background-color: #083471;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_073a1_row2_col4, #T_073a1_row3_col4, #T_073a1_row9_col4, #T_073a1_row20_col3 {\n",
              "  background-color: #f4f9fe;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_073a1_row4_col1, #T_073a1_row23_col2 {\n",
              "  background-color: #083c7d;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_073a1_row4_col4, #T_073a1_row21_col3 {\n",
              "  background-color: #f3f8fe;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_073a1_row5_col1 {\n",
              "  background-color: #083e81;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_073a1_row5_col2, #T_073a1_row21_col1 {\n",
              "  background-color: #08326e;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_073a1_row5_col4 {\n",
              "  background-color: #aed1e7;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_073a1_row6_col1 {\n",
              "  background-color: #083d7f;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_073a1_row7_col1, #T_073a1_row8_col1, #T_073a1_row10_col1, #T_073a1_row11_col1 {\n",
              "  background-color: #084285;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_073a1_row7_col2, #T_073a1_row8_col2, #T_073a1_row9_col2, #T_073a1_row10_col2, #T_073a1_row11_col2, #T_073a1_row24_col1 {\n",
              "  background-color: #08316d;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_073a1_row7_col4 {\n",
              "  background-color: #ccdff1;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_073a1_row8_col4, #T_073a1_row12_col4, #T_073a1_row24_col3 {\n",
              "  background-color: #eef5fc;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_073a1_row9_col1, #T_073a1_row35_col2 {\n",
              "  background-color: #084387;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_073a1_row10_col4 {\n",
              "  background-color: #eaf2fb;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_073a1_row11_col4, #T_073a1_row16_col4, #T_073a1_row32_col4 {\n",
              "  background-color: #f5fafe;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_073a1_row12_col1, #T_073a1_row13_col1, #T_073a1_row14_col1, #T_073a1_row15_col1, #T_073a1_row16_col1, #T_073a1_row17_col1, #T_073a1_row18_col1, #T_073a1_row19_col1, #T_073a1_row27_col1, #T_073a1_row28_col1, #T_073a1_row29_col1, #T_073a1_row32_col1, #T_073a1_row33_col1, #T_073a1_row34_col1 {\n",
              "  background-color: #084990;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_073a1_row12_col2, #T_073a1_row13_col2, #T_073a1_row14_col2, #T_073a1_row15_col2, #T_073a1_row16_col2, #T_073a1_row17_col2, #T_073a1_row18_col2, #T_073a1_row19_col2, #T_073a1_row25_col4, #T_073a1_row26_col1, #T_073a1_row27_col2, #T_073a1_row28_col2, #T_073a1_row30_col3, #T_073a1_row32_col2, #T_073a1_row33_col2 {\n",
              "  background-color: #08306b;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_073a1_row13_col4 {\n",
              "  background-color: #7fb9da;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_073a1_row14_col4 {\n",
              "  background-color: #5ba3d0;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_073a1_row15_col4 {\n",
              "  background-color: #77b5d9;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_073a1_row17_col3, #T_073a1_row17_col4, #T_073a1_row18_col3, #T_073a1_row34_col4 {\n",
              "  background-color: #f6faff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_073a1_row19_col4, #T_073a1_row22_col3 {\n",
              "  background-color: #f2f8fd;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_073a1_row20_col1 {\n",
              "  background-color: #084a91;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_073a1_row20_col2 {\n",
              "  background-color: #6caed6;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_073a1_row21_col2 {\n",
              "  background-color: #3383be;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_073a1_row22_col1, #T_073a1_row23_col1, #T_073a1_row25_col1, #T_073a1_row25_col2 {\n",
              "  background-color: #084082;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_073a1_row22_col2 {\n",
              "  background-color: #083b7c;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_073a1_row22_col4 {\n",
              "  background-color: #083776;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_073a1_row23_col3 {\n",
              "  background-color: #f0f6fd;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_073a1_row23_col4 {\n",
              "  background-color: #083370;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_073a1_row24_col2 {\n",
              "  background-color: #4a98c9;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_073a1_row25_col3 {\n",
              "  background-color: #ecf4fb;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_073a1_row26_col2 {\n",
              "  background-color: #5ca4d0;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_073a1_row26_col3 {\n",
              "  background-color: #e3eef8;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_073a1_row27_col3, #T_073a1_row28_col3 {\n",
              "  background-color: #dce9f6;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_073a1_row29_col2, #T_073a1_row34_col2 {\n",
              "  background-color: #08519c;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_073a1_row29_col3 {\n",
              "  background-color: #c7dcef;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_073a1_row31_col1, #T_073a1_row31_col2, #T_073a1_row31_col3, #T_073a1_row31_col4, #T_073a1_row32_col3, #T_073a1_row33_col3, #T_073a1_row34_col3, #T_073a1_row35_col3, #T_073a1_row36_col1, #T_073a1_row36_col2, #T_073a1_row36_col3, #T_073a1_row36_col4, #T_073a1_row37_col1, #T_073a1_row37_col2, #T_073a1_row37_col3, #T_073a1_row37_col4, #T_073a1_row38_col1, #T_073a1_row38_col2, #T_073a1_row38_col3, #T_073a1_row38_col4 {\n",
              "  background-color: #000000;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_073a1_row35_col1 {\n",
              "  background-color: #08488e;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_073a1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_073a1_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
              "      <th id=\"T_073a1_level0_col1\" class=\"col_heading level0 col1\" >Precision</th>\n",
              "      <th id=\"T_073a1_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
              "      <th id=\"T_073a1_level0_col3\" class=\"col_heading level0 col3\" >Log Loss</th>\n",
              "      <th id=\"T_073a1_level0_col4\" class=\"col_heading level0 col4\" >Time (s)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_073a1_row0_col0\" class=\"data row0 col0\" >XGBClassifier</td>\n",
              "      <td id=\"T_073a1_row0_col1\" class=\"data row0 col1\" >0.934732</td>\n",
              "      <td id=\"T_073a1_row0_col2\" class=\"data row0 col2\" >0.977485</td>\n",
              "      <td id=\"T_073a1_row0_col3\" class=\"data row0 col3\" >0.196070</td>\n",
              "      <td id=\"T_073a1_row0_col4\" class=\"data row0 col4\" >1.359246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_073a1_row1_col0\" class=\"data row1 col0\" >HistGradientBoostingClassifier</td>\n",
              "      <td id=\"T_073a1_row1_col1\" class=\"data row1 col1\" >0.933548</td>\n",
              "      <td id=\"T_073a1_row1_col2\" class=\"data row1 col2\" >0.979148</td>\n",
              "      <td id=\"T_073a1_row1_col3\" class=\"data row1 col3\" >0.199815</td>\n",
              "      <td id=\"T_073a1_row1_col4\" class=\"data row1 col4\" >2.780254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_073a1_row2_col0\" class=\"data row2 col0\" >HistGradientBoostingClassifier</td>\n",
              "      <td id=\"T_073a1_row2_col1\" class=\"data row2 col1\" >0.928338</td>\n",
              "      <td id=\"T_073a1_row2_col2\" class=\"data row2 col2\" >0.983046</td>\n",
              "      <td id=\"T_073a1_row2_col3\" class=\"data row2 col3\" >0.210503</td>\n",
              "      <td id=\"T_073a1_row2_col4\" class=\"data row2 col4\" >1.705726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_073a1_row3_col0\" class=\"data row3 col0\" >LGBMClassifier</td>\n",
              "      <td id=\"T_073a1_row3_col1\" class=\"data row3 col1\" >0.928362</td>\n",
              "      <td id=\"T_073a1_row3_col2\" class=\"data row3 col2\" >0.984109</td>\n",
              "      <td id=\"T_073a1_row3_col3\" class=\"data row3 col3\" >0.210669</td>\n",
              "      <td id=\"T_073a1_row3_col4\" class=\"data row3 col4\" >1.673996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_073a1_row4_col0\" class=\"data row4 col0\" >DecisionTreeClassifier</td>\n",
              "      <td id=\"T_073a1_row4_col1\" class=\"data row4 col1\" >0.922815</td>\n",
              "      <td id=\"T_073a1_row4_col2\" class=\"data row4 col2\" >0.981247</td>\n",
              "      <td id=\"T_073a1_row4_col3\" class=\"data row4 col3\" >0.220118</td>\n",
              "      <td id=\"T_073a1_row4_col4\" class=\"data row4 col4\" >1.763219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_073a1_row5_col0\" class=\"data row5 col0\" >GradientBoostingClassifier</td>\n",
              "      <td id=\"T_073a1_row5_col1\" class=\"data row5 col1\" >0.914527</td>\n",
              "      <td id=\"T_073a1_row5_col2\" class=\"data row5 col2\" >0.989261</td>\n",
              "      <td id=\"T_073a1_row5_col3\" class=\"data row5 col3\" >0.227846</td>\n",
              "      <td id=\"T_073a1_row5_col4\" class=\"data row5 col4\" >28.772829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_073a1_row6_col0\" class=\"data row6 col0\" >DecisionTreeClassifier</td>\n",
              "      <td id=\"T_073a1_row6_col1\" class=\"data row6 col1\" >0.918772</td>\n",
              "      <td id=\"T_073a1_row6_col2\" class=\"data row6 col2\" >0.984136</td>\n",
              "      <td id=\"T_073a1_row6_col3\" class=\"data row6 col3\" >0.237053</td>\n",
              "      <td id=\"T_073a1_row6_col4\" class=\"data row6 col4\" >1.363050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_073a1_row7_col0\" class=\"data row7 col0\" >GradientBoostingClassifier</td>\n",
              "      <td id=\"T_073a1_row7_col1\" class=\"data row7 col1\" >0.902793</td>\n",
              "      <td id=\"T_073a1_row7_col2\" class=\"data row7 col2\" >0.995639</td>\n",
              "      <td id=\"T_073a1_row7_col3\" class=\"data row7 col3\" >0.241779</td>\n",
              "      <td id=\"T_073a1_row7_col4\" class=\"data row7 col4\" >19.609189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_073a1_row8_col0\" class=\"data row8 col0\" >RandomForestClassifier</td>\n",
              "      <td id=\"T_073a1_row8_col1\" class=\"data row8 col1\" >0.904737</td>\n",
              "      <td id=\"T_073a1_row8_col2\" class=\"data row8 col2\" >0.994330</td>\n",
              "      <td id=\"T_073a1_row8_col3\" class=\"data row8 col3\" >0.254041</td>\n",
              "      <td id=\"T_073a1_row8_col4\" class=\"data row8 col4\" >4.294132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_073a1_row9_col0\" class=\"data row9 col0\" >RandomForestClassifier</td>\n",
              "      <td id=\"T_073a1_row9_col1\" class=\"data row9 col1\" >0.901528</td>\n",
              "      <td id=\"T_073a1_row9_col2\" class=\"data row9 col2\" >0.995448</td>\n",
              "      <td id=\"T_073a1_row9_col3\" class=\"data row9 col3\" >0.256690</td>\n",
              "      <td id=\"T_073a1_row9_col4\" class=\"data row9 col4\" >1.707813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
              "      <td id=\"T_073a1_row10_col0\" class=\"data row10 col0\" >BaggingClassifier</td>\n",
              "      <td id=\"T_073a1_row10_col1\" class=\"data row10 col1\" >0.901696</td>\n",
              "      <td id=\"T_073a1_row10_col2\" class=\"data row10 col2\" >0.995584</td>\n",
              "      <td id=\"T_073a1_row10_col3\" class=\"data row10 col3\" >0.264355</td>\n",
              "      <td id=\"T_073a1_row10_col4\" class=\"data row10 col4\" >6.234128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
              "      <td id=\"T_073a1_row11_col0\" class=\"data row11 col0\" >DecisionTreeClassifier</td>\n",
              "      <td id=\"T_073a1_row11_col1\" class=\"data row11 col1\" >0.902423</td>\n",
              "      <td id=\"T_073a1_row11_col2\" class=\"data row11 col2\" >0.993731</td>\n",
              "      <td id=\"T_073a1_row11_col3\" class=\"data row11 col3\" >0.266293</td>\n",
              "      <td id=\"T_073a1_row11_col4\" class=\"data row11 col4\" >0.949644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
              "      <td id=\"T_073a1_row12_col0\" class=\"data row12 col0\" >LogisticRegression</td>\n",
              "      <td id=\"T_073a1_row12_col1\" class=\"data row12 col1\" >0.877634</td>\n",
              "      <td id=\"T_073a1_row12_col2\" class=\"data row12 col2\" >0.997819</td>\n",
              "      <td id=\"T_073a1_row12_col3\" class=\"data row12 col3\" >0.295402</td>\n",
              "      <td id=\"T_073a1_row12_col4\" class=\"data row12 col4\" >3.899219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
              "      <td id=\"T_073a1_row13_col0\" class=\"data row13 col0\" >BaggingClassifier</td>\n",
              "      <td id=\"T_073a1_row13_col1\" class=\"data row13 col1\" >0.877734</td>\n",
              "      <td id=\"T_073a1_row13_col2\" class=\"data row13 col2\" >0.997765</td>\n",
              "      <td id=\"T_073a1_row13_col3\" class=\"data row13 col3\" >0.295478</td>\n",
              "      <td id=\"T_073a1_row13_col4\" class=\"data row13 col4\" >39.867280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
              "      <td id=\"T_073a1_row14_col0\" class=\"data row14 col0\" >LogisticRegression</td>\n",
              "      <td id=\"T_073a1_row14_col1\" class=\"data row14 col1\" >0.877839</td>\n",
              "      <td id=\"T_073a1_row14_col2\" class=\"data row14 col2\" >0.997765</td>\n",
              "      <td id=\"T_073a1_row14_col3\" class=\"data row14 col3\" >0.296950</td>\n",
              "      <td id=\"T_073a1_row14_col4\" class=\"data row14 col4\" >48.663970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
              "      <td id=\"T_073a1_row15_col0\" class=\"data row15 col0\" >LogisticRegression</td>\n",
              "      <td id=\"T_073a1_row15_col1\" class=\"data row15 col1\" >0.877860</td>\n",
              "      <td id=\"T_073a1_row15_col2\" class=\"data row15 col2\" >0.997765</td>\n",
              "      <td id=\"T_073a1_row15_col3\" class=\"data row15 col3\" >0.296953</td>\n",
              "      <td id=\"T_073a1_row15_col4\" class=\"data row15 col4\" >41.610969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
              "      <td id=\"T_073a1_row16_col0\" class=\"data row16 col0\" >SGDClassifier</td>\n",
              "      <td id=\"T_073a1_row16_col1\" class=\"data row16 col1\" >0.876744</td>\n",
              "      <td id=\"T_073a1_row16_col2\" class=\"data row16 col2\" >0.998528</td>\n",
              "      <td id=\"T_073a1_row16_col3\" class=\"data row16 col3\" >0.300413</td>\n",
              "      <td id=\"T_073a1_row16_col4\" class=\"data row16 col4\" >0.730341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
              "      <td id=\"T_073a1_row17_col0\" class=\"data row17 col0\" >ExtraTreesClassifier</td>\n",
              "      <td id=\"T_073a1_row17_col1\" class=\"data row17 col1\" >0.875188</td>\n",
              "      <td id=\"T_073a1_row17_col2\" class=\"data row17 col2\" >1.000000</td>\n",
              "      <td id=\"T_073a1_row17_col3\" class=\"data row17 col3\" >0.331129</td>\n",
              "      <td id=\"T_073a1_row17_col4\" class=\"data row17 col4\" >0.593977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
              "      <td id=\"T_073a1_row18_col0\" class=\"data row18 col0\" >ExtraTreesClassifier</td>\n",
              "      <td id=\"T_073a1_row18_col1\" class=\"data row18 col1\" >0.875188</td>\n",
              "      <td id=\"T_073a1_row18_col2\" class=\"data row18 col2\" >1.000000</td>\n",
              "      <td id=\"T_073a1_row18_col3\" class=\"data row18 col3\" >0.339522</td>\n",
              "      <td id=\"T_073a1_row18_col4\" class=\"data row18 col4\" >0.299565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
              "      <td id=\"T_073a1_row19_col0\" class=\"data row19 col0\" >SGDClassifier</td>\n",
              "      <td id=\"T_073a1_row19_col1\" class=\"data row19 col1\" >0.875583</td>\n",
              "      <td id=\"T_073a1_row19_col2\" class=\"data row19 col2\" >0.998446</td>\n",
              "      <td id=\"T_073a1_row19_col3\" class=\"data row19 col3\" >0.590779</td>\n",
              "      <td id=\"T_073a1_row19_col4\" class=\"data row19 col4\" >2.095164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
              "      <td id=\"T_073a1_row20_col0\" class=\"data row20 col0\" >DummyClassifier</td>\n",
              "      <td id=\"T_073a1_row20_col1\" class=\"data row20 col1\" >0.872564</td>\n",
              "      <td id=\"T_073a1_row20_col2\" class=\"data row20 col2\" >0.496634</td>\n",
              "      <td id=\"T_073a1_row20_col3\" class=\"data row20 col3\" >0.693147</td>\n",
              "      <td id=\"T_073a1_row20_col4\" class=\"data row20 col4\" >0.002735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
              "      <td id=\"T_073a1_row21_col0\" class=\"data row21 col0\" >BernoulliNB</td>\n",
              "      <td id=\"T_073a1_row21_col1\" class=\"data row21 col1\" >0.959799</td>\n",
              "      <td id=\"T_073a1_row21_col2\" class=\"data row21 col2\" >0.682667</td>\n",
              "      <td id=\"T_073a1_row21_col3\" class=\"data row21 col3\" >0.930615</td>\n",
              "      <td id=\"T_073a1_row21_col4\" class=\"data row21 col4\" >0.177987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
              "      <td id=\"T_073a1_row22_col0\" class=\"data row22 col0\" >KNeighborsClassifier</td>\n",
              "      <td id=\"T_073a1_row22_col1\" class=\"data row22 col1\" >0.910506</td>\n",
              "      <td id=\"T_073a1_row22_col2\" class=\"data row22 col2\" >0.955079</td>\n",
              "      <td id=\"T_073a1_row22_col3\" class=\"data row22 col3\" >0.994836</td>\n",
              "      <td id=\"T_073a1_row22_col4\" class=\"data row22 col4\" >86.222761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
              "      <td id=\"T_073a1_row23_col0\" class=\"data row23 col0\" >KNeighborsClassifier</td>\n",
              "      <td id=\"T_073a1_row23_col1\" class=\"data row23 col1\" >0.910583</td>\n",
              "      <td id=\"T_073a1_row23_col2\" class=\"data row23 col2\" >0.949873</td>\n",
              "      <td id=\"T_073a1_row23_col3\" class=\"data row23 col3\" >1.298598</td>\n",
              "      <td id=\"T_073a1_row23_col4\" class=\"data row23 col4\" >87.611902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
              "      <td id=\"T_073a1_row24_col0\" class=\"data row24 col0\" >NearestCentroid</td>\n",
              "      <td id=\"T_073a1_row24_col1\" class=\"data row24 col1\" >0.963017</td>\n",
              "      <td id=\"T_073a1_row24_col2\" class=\"data row24 col2\" >0.598332</td>\n",
              "      <td id=\"T_073a1_row24_col3\" class=\"data row24 col3\" >1.742116</td>\n",
              "      <td id=\"T_073a1_row24_col4\" class=\"data row24 col4\" >0.140500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
              "      <td id=\"T_073a1_row25_col0\" class=\"data row25 col0\" >KNeighborsClassifier</td>\n",
              "      <td id=\"T_073a1_row25_col1\" class=\"data row25 col1\" >0.911653</td>\n",
              "      <td id=\"T_073a1_row25_col2\" class=\"data row25 col2\" >0.939161</td>\n",
              "      <td id=\"T_073a1_row25_col3\" class=\"data row25 col3\" >2.018997</td>\n",
              "      <td id=\"T_073a1_row25_col4\" class=\"data row25 col4\" >88.732095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
              "      <td id=\"T_073a1_row26_col0\" class=\"data row26 col0\" >GaussianNB</td>\n",
              "      <td id=\"T_073a1_row26_col1\" class=\"data row26 col1\" >0.969805</td>\n",
              "      <td id=\"T_073a1_row26_col2\" class=\"data row26 col2\" >0.546297</td>\n",
              "      <td id=\"T_073a1_row26_col3\" class=\"data row26 col3\" >3.446790</td>\n",
              "      <td id=\"T_073a1_row26_col4\" class=\"data row26 col4\" >0.153859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
              "      <td id=\"T_073a1_row27_col0\" class=\"data row27 col0\" >DummyClassifier</td>\n",
              "      <td id=\"T_073a1_row27_col1\" class=\"data row27 col1\" >0.875188</td>\n",
              "      <td id=\"T_073a1_row27_col2\" class=\"data row27 col2\" >1.000000</td>\n",
              "      <td id=\"T_073a1_row27_col3\" class=\"data row27 col3\" >4.498685</td>\n",
              "      <td id=\"T_073a1_row27_col4\" class=\"data row27 col4\" >0.002869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
              "      <td id=\"T_073a1_row28_col0\" class=\"data row28 col0\" >DummyClassifier</td>\n",
              "      <td id=\"T_073a1_row28_col1\" class=\"data row28 col1\" >0.875188</td>\n",
              "      <td id=\"T_073a1_row28_col2\" class=\"data row28 col2\" >1.000000</td>\n",
              "      <td id=\"T_073a1_row28_col3\" class=\"data row28 col3\" >4.498685</td>\n",
              "      <td id=\"T_073a1_row28_col4\" class=\"data row28 col4\" >0.002444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
              "      <td id=\"T_073a1_row29_col0\" class=\"data row29 col0\" >DummyClassifier</td>\n",
              "      <td id=\"T_073a1_row29_col1\" class=\"data row29 col1\" >0.876123</td>\n",
              "      <td id=\"T_073a1_row29_col2\" class=\"data row29 col2\" >0.874833</td>\n",
              "      <td id=\"T_073a1_row29_col3\" class=\"data row29 col3\" >7.809931</td>\n",
              "      <td id=\"T_073a1_row29_col4\" class=\"data row29 col4\" >0.004793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
              "      <td id=\"T_073a1_row30_col0\" class=\"data row30 col0\" >DummyClassifier</td>\n",
              "      <td id=\"T_073a1_row30_col1\" class=\"data row30 col1\" >0.000000</td>\n",
              "      <td id=\"T_073a1_row30_col2\" class=\"data row30 col2\" >0.000000</td>\n",
              "      <td id=\"T_073a1_row30_col3\" class=\"data row30 col3\" >31.544968</td>\n",
              "      <td id=\"T_073a1_row30_col4\" class=\"data row30 col4\" >0.002385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
              "      <td id=\"T_073a1_row31_col0\" class=\"data row31 col0\" >LogisticRegression</td>\n",
              "      <td id=\"T_073a1_row31_col1\" class=\"data row31 col1\" >nan</td>\n",
              "      <td id=\"T_073a1_row31_col2\" class=\"data row31 col2\" >nan</td>\n",
              "      <td id=\"T_073a1_row31_col3\" class=\"data row31 col3\" >nan</td>\n",
              "      <td id=\"T_073a1_row31_col4\" class=\"data row31 col4\" >nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
              "      <td id=\"T_073a1_row32_col0\" class=\"data row32 col0\" >SGDClassifier</td>\n",
              "      <td id=\"T_073a1_row32_col1\" class=\"data row32 col1\" >0.875313</td>\n",
              "      <td id=\"T_073a1_row32_col2\" class=\"data row32 col2\" >0.999046</td>\n",
              "      <td id=\"T_073a1_row32_col3\" class=\"data row32 col3\" >nan</td>\n",
              "      <td id=\"T_073a1_row32_col4\" class=\"data row32 col4\" >1.008271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
              "      <td id=\"T_073a1_row33_col0\" class=\"data row33 col0\" >RidgeClassifier</td>\n",
              "      <td id=\"T_073a1_row33_col1\" class=\"data row33 col1\" >0.875200</td>\n",
              "      <td id=\"T_073a1_row33_col2\" class=\"data row33 col2\" >0.999918</td>\n",
              "      <td id=\"T_073a1_row33_col3\" class=\"data row33 col3\" >nan</td>\n",
              "      <td id=\"T_073a1_row33_col4\" class=\"data row33 col4\" >0.121811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
              "      <td id=\"T_073a1_row34_col0\" class=\"data row34 col0\" >PassiveAggressiveClassifier</td>\n",
              "      <td id=\"T_073a1_row34_col1\" class=\"data row34 col1\" >0.878143</td>\n",
              "      <td id=\"T_073a1_row34_col2\" class=\"data row34 col2\" >0.871944</td>\n",
              "      <td id=\"T_073a1_row34_col3\" class=\"data row34 col3\" >nan</td>\n",
              "      <td id=\"T_073a1_row34_col4\" class=\"data row34 col4\" >0.496906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
              "      <td id=\"T_073a1_row35_col0\" class=\"data row35 col0\" >Perceptron</td>\n",
              "      <td id=\"T_073a1_row35_col1\" class=\"data row35 col1\" >0.879624</td>\n",
              "      <td id=\"T_073a1_row35_col2\" class=\"data row35 col2\" >0.928776</td>\n",
              "      <td id=\"T_073a1_row35_col3\" class=\"data row35 col3\" >nan</td>\n",
              "      <td id=\"T_073a1_row35_col4\" class=\"data row35 col4\" >0.313927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
              "      <td id=\"T_073a1_row36_col0\" class=\"data row36 col0\" >MultinomialNB</td>\n",
              "      <td id=\"T_073a1_row36_col1\" class=\"data row36 col1\" >nan</td>\n",
              "      <td id=\"T_073a1_row36_col2\" class=\"data row36 col2\" >nan</td>\n",
              "      <td id=\"T_073a1_row36_col3\" class=\"data row36 col3\" >nan</td>\n",
              "      <td id=\"T_073a1_row36_col4\" class=\"data row36 col4\" >nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
              "      <td id=\"T_073a1_row37_col0\" class=\"data row37 col0\" >ComplementNB</td>\n",
              "      <td id=\"T_073a1_row37_col1\" class=\"data row37 col1\" >nan</td>\n",
              "      <td id=\"T_073a1_row37_col2\" class=\"data row37 col2\" >nan</td>\n",
              "      <td id=\"T_073a1_row37_col3\" class=\"data row37 col3\" >nan</td>\n",
              "      <td id=\"T_073a1_row37_col4\" class=\"data row37 col4\" >nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_073a1_level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
              "      <td id=\"T_073a1_row38_col0\" class=\"data row38 col0\" >RadiusNeighborsClassifier</td>\n",
              "      <td id=\"T_073a1_row38_col1\" class=\"data row38 col1\" >nan</td>\n",
              "      <td id=\"T_073a1_row38_col2\" class=\"data row38 col2\" >nan</td>\n",
              "      <td id=\"T_073a1_row38_col3\" class=\"data row38 col3\" >nan</td>\n",
              "      <td id=\"T_073a1_row38_col4\" class=\"data row38 col4\" >nan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.to_csv('model_comparison_results.csv', index=False)\n"
      ],
      "metadata": {
        "id": "PAYcWbUXhb4O"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Prepare data for Naive Bayes\n",
        "minmax_scaler = MinMaxScaler()\n",
        "X_train_nb = minmax_scaler.fit_transform(X_train)\n",
        "X_test_nb = minmax_scaler.transform(X_test)\n",
        "\n",
        "# Define models\n",
        "nb_models = [\n",
        "    ('MultinomialNB', MultinomialNB()),\n",
        "    ('ComplementNB', ComplementNB())\n",
        "]\n",
        "\n",
        "# Evaluate them\n",
        "for name, model in nb_models:\n",
        "    try:\n",
        "        start = time.time()\n",
        "        model.fit(X_train_nb, y_train)\n",
        "        y_pred = model.predict(X_test_nb)\n",
        "        y_prob = model.predict_proba(X_test_nb)\n",
        "        end = time.time()\n",
        "\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        logloss = log_loss(y_test, y_prob)\n",
        "        elapsed = end - start\n",
        "\n",
        "        results_df.loc[len(results_df)] = [name, precision, recall, logloss, elapsed]\n",
        "        print(f\"{name} ✔️ Reprocessed — Time: {elapsed:.2f}s\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"{name} ❌ Error after fix: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiKcXS9Fhihi",
        "outputId": "49555493-9f66-4649-8f9a-f7ea634d3f3c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultinomialNB ✔️ Reprocessed — Time: 0.05s\n",
            "ComplementNB ✔️ Reprocessed — Time: 0.08s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import RadiusNeighborsClassifier\n",
        "\n",
        "try:\n",
        "    model_name = 'RadiusNeighborsClassifier'\n",
        "    start = time.time()\n",
        "    radius_model = RadiusNeighborsClassifier(radius=10.0)\n",
        "    radius_model.fit(X_train_scaled, y_train)\n",
        "    y_pred = radius_model.predict(X_test_scaled)\n",
        "    y_prob = radius_model.predict_proba(X_test_scaled)\n",
        "    end = time.time()\n",
        "\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    logloss = log_loss(y_test, y_prob)\n",
        "    elapsed = end - start\n",
        "\n",
        "    results_df.loc[len(results_df)] = [model_name, precision, recall, logloss, elapsed]\n",
        "    print(f\"{model_name} ✔️ Reprocessed — Time: {elapsed:.2f}s\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"{model_name} ❌ Error after fix: {e}\")\n"
      ],
      "metadata": {
        "id": "IRiQPj1liUxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values(by='Log Loss', ascending=True).reset_index(drop=True)\n",
        "results_df.style.background_gradient(cmap='Blues')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "1QXtgZoCiXDb",
        "outputId": "c2dfb7fd-716c-4966-af69-cc64ebb24468"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-314d59c3e94f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresults_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Log Loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackground_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Blues'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Replace with your actual trained model variable\n",
        "final_model = XGBClassifier()\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "# Save the trained model\n",
        "joblib.dump(final_model, 'final_model.pkl')\n",
        "\n",
        "# If you used a scaler\n",
        "joblib.dump(scaler, 'scaler.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "9E-vUXycy8bK",
        "outputId": "9d0aed85-b587-4e5d-89c1-50253516a209"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'XGBClassifier' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-cd335d79b221>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Replace with your actual trained model variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfinal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'XGBClassifier' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "results_df = pd.read_csv('model_comparison_results.csv')\n"
      ],
      "metadata": {
        "id": "R8HH5IM0zC_C"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Select model with highest recall\n",
        "best_model = results_df.loc[results_df['Recall'].idxmax()]\n",
        "\n",
        "print(\"Best model based on Recall:\")\n",
        "print(best_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huV0v2zCzi5u",
        "outputId": "a0e78ee2-bca4-43f6-da0d-b63be754e209"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model based on Recall:\n",
            "Model        ExtraTreesClassifier\n",
            "Precision                0.875188\n",
            "Recall                        1.0\n",
            "Log Loss                 0.331129\n",
            "Time (s)                 0.593977\n",
            "Name: 17, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file containing model evaluation metrics\n",
        "results_df = pd.read_csv('model_comparison_results.csv')\n",
        "\n",
        "# Drop rows where Precision is NaN (if any)\n",
        "results_df = results_df.dropna(subset=['Precision'])\n",
        "\n",
        "# Find the row with the highest Precision\n",
        "best_model_row = results_df.loc[results_df['Precision'].idxmax()]\n",
        "\n",
        "print(\"Best model based on Precision:\")\n",
        "print(best_model_row)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jaWIlOMzm_R",
        "outputId": "b546eca0-d456-4d09-d2c8-4b86bcad3d20"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model based on Precision:\n",
            "Model        GaussianNB\n",
            "Precision      0.969805\n",
            "Recall         0.546297\n",
            "Log Loss        3.44679\n",
            "Time (s)       0.153859\n",
            "Name: 26, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load your results CSV\n",
        "results_df = pd.read_csv('model_comparison_results.csv')\n",
        "\n",
        "# Drop rows with NaN in critical columns\n",
        "results_df = results_df.dropna(subset=['Precision', 'Recall', ])\n",
        "\n",
        "# Min-max scale Precision, Recall, and LogLoss (LogLoss is to be minimized, so invert it)\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Scale Precision and Recall normally\n",
        "results_df[['Precision_scaled', 'Recall_scaled']] = scaler.fit_transform(results_df[['Precision', 'Recall']])\n",
        "\n",
        "\n",
        "\n",
        "# Define weights (you can adjust these as per your priority)\n",
        "w_precision = 0.4\n",
        "w_recall = 0.4\n",
        "\n",
        "\n",
        "# Calculate combined score\n",
        "results_df['Combined_Score'] = (\n",
        "    w_precision * results_df['Precision_scaled'] +\n",
        "    w_recall * results_df['Recall_scaled']\n",
        "\n",
        ")\n",
        "\n",
        "# Select the best model\n",
        "best_model_row = results_df.loc[results_df['Combined_Score'].idxmax()]\n",
        "\n",
        "print(\"Best model balancing Precision, Recall, and Log Loss:\")\n",
        "print(best_model_row)\n",
        "\n",
        "# Get model name\n",
        "best_model_name = best_model_row['Model']  # Adjust if your column name is different\n",
        "print(f\"Selected model: {best_model_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWb7dgibz1rg",
        "outputId": "d28eda0b-e345-48d5-f9a1-0657adadf636"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model balancing Precision, Recall, and Log Loss:\n",
            "Model               HistGradientBoostingClassifier\n",
            "Precision                                 0.933548\n",
            "Recall                                    0.979148\n",
            "Log Loss                                  0.199815\n",
            "Time (s)                                  2.780254\n",
            "Precision_scaled                          0.962614\n",
            "Recall_scaled                             0.979148\n",
            "Combined_Score                            0.776705\n",
            "Name: 1, dtype: object\n",
            "Selected model: HistGradientBoostingClassifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load your CSV results\n",
        "results_df = pd.read_csv('model_comparison_results.csv')\n",
        "\n",
        "# Drop rows with NaN in critical columns\n",
        "results_df = results_df.dropna(subset=['Precision', 'Recall', 'Time'])\n",
        "\n",
        "# Min-max scale Precision and Recall normally\n",
        "scaler = MinMaxScaler()\n",
        "results_df[['Precision_scaled', 'Recall_scaled']] = scaler.fit_transform(results_df[['Precision', 'Recall']])\n",
        "\n",
        "# Scale time and invert because lower time is better\n",
        "time_scaled = scaler.fit_transform(results_df[['Time']])\n",
        "results_df['Time_scaled'] = 1 - time_scaled  # invert to make higher better\n",
        "\n",
        "# Weights for each metric - adjust if needed\n",
        "w_precision = 0.4\n",
        "w_recall = 0.4\n",
        "w_time = 0.2\n",
        "\n",
        "# Combined score calculation\n",
        "results_df['Combined_Score'] = (\n",
        "    w_precision * results_df['Precision_scaled'] +\n",
        "    w_recall * results_df['Recall_scaled'] +\n",
        "    w_time * results_df['Time_scaled']\n",
        ")\n",
        "\n",
        "# Find best model based on combined score\n",
        "best_model_row = results_df.loc[results_df['Combined_Score'].idxmax()]\n",
        "\n",
        "print(\"Best model balancing Precision, Recall, and Execution Time:\")\n",
        "print(best_model_row)\n",
        "\n",
        "# Model name\n",
        "best_model_name = best_model_row['Model']\n",
        "print(f\"Selected model: {best_model_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "dcBvxvOS0LFe",
        "outputId": "e9aa4605-84df-491d-d72c-1a127bbdf0aa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "['Time']",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-502c16958476>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Drop rows with NaN in critical columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mresults_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Precision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Recall'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Min-max scale Precision and Recall normally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdropna\u001b[0;34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[0m\n\u001b[1;32m   6668\u001b[0m             \u001b[0mcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6669\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6670\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6671\u001b[0m             \u001b[0magg_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: ['Time']"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Replace 'results.csv' with your actual file path\n",
        "df = pd.read_csv('model_comparison_results.csv')\n"
      ],
      "metadata": {
        "id": "BQyH7WNp04tj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqB4FCXM1kPq",
        "outputId": "50a64d9e-4313-4f59-eaf0-2fd79c9d8e62"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            Model  Precision    Recall  Log Loss  Time (s)\n",
            "0                   XGBClassifier   0.934732  0.977485  0.196070  1.359246\n",
            "1  HistGradientBoostingClassifier   0.933548  0.979148  0.199815  2.780254\n",
            "2  HistGradientBoostingClassifier   0.928338  0.983046  0.210503  1.705726\n",
            "3                  LGBMClassifier   0.928362  0.984109  0.210669  1.673996\n",
            "4          DecisionTreeClassifier   0.922815  0.981247  0.220118  1.763219\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_sorted = df.sort_values(by=['Precision', 'Recall', 'PredictionTime'], ascending=[False, False, True])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "7XP4J5kG1uUL",
        "outputId": "c1b80890-2afe-4daf-f45f-64f49730728b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'PredictionTime'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-c0d0bdb40b0b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Precision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Recall'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PredictionTime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   7170\u001b[0m             )\n\u001b[1;32m   7171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7172\u001b[0;31m             \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7174\u001b[0m             \u001b[0;31m# need to rewrap columns in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   7170\u001b[0m             )\n\u001b[1;32m   7171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7172\u001b[0;31m             \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7174\u001b[0m             \u001b[0;31m# need to rewrap columns in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'PredictionTime'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file (replace 'results.csv' with your actual file path)\n",
        "df = pd.read_csv('model_comparison_results.csv')\n",
        "\n",
        "# Display first few rows to verify\n",
        "print(df.head())\n",
        "\n",
        "# Sort by Precision (desc), Recall (desc), and Time (asc)\n",
        "df_sorted = df.sort_values(by=['Precision', 'Recall', 'Time (s)'], ascending=[False, False, True])\n",
        "\n",
        "# Get the best model row\n",
        "best_model_row = df_sorted.iloc[0]\n",
        "print(\"Best model based on Precision, Recall and Time:\")\n",
        "print(best_model_row)\n",
        "\n",
        "# Extract best model name\n",
        "best_model_name = best_model_row['Model']\n",
        "\n",
        "print(f\"Selected model: {best_model_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUaZJaY71waq",
        "outputId": "1d53c9c0-dfe0-4485-8f67-b4f7fd50fc19"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            Model  Precision    Recall  Log Loss  Time (s)\n",
            "0                   XGBClassifier   0.934732  0.977485  0.196070  1.359246\n",
            "1  HistGradientBoostingClassifier   0.933548  0.979148  0.199815  2.780254\n",
            "2  HistGradientBoostingClassifier   0.928338  0.983046  0.210503  1.705726\n",
            "3                  LGBMClassifier   0.928362  0.984109  0.210669  1.673996\n",
            "4          DecisionTreeClassifier   0.922815  0.981247  0.220118  1.763219\n",
            "Best model based on Precision, Recall and Time:\n",
            "Model        GaussianNB\n",
            "Precision      0.969805\n",
            "Recall         0.546297\n",
            "Log Loss        3.44679\n",
            "Time (s)       0.153859\n",
            "Name: 26, dtype: object\n",
            "Selected model: GaussianNB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "model_filename = f\"{best_model_name}.pkl\"\n",
        "best_model = joblib.load(model_filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "mTcnserV2BVP",
        "outputId": "8f398a2e-4667-47df-d5c6-a58ff790ea43"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'GaussianNB.pkl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-96e756ce16ac>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{best_model_name}.pkl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode, ensure_native_byte_order)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_native_byte_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_native_byte_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             with _validate_fileobject_and_memmap(f, filename, mmap_mode) as (\n\u001b[1;32m    737\u001b[0m                 \u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'GaussianNB.pkl'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "model_filename = f\"{best_model_name}.pkl\"\n",
        "best_model = joblib.load(model_filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "mQygUau62NCs",
        "outputId": "34af06c1-8e23-4ea6-d779-64caffafc2ad"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'GaussianNB.pkl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-96e756ce16ac>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{best_model_name}.pkl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode, ensure_native_byte_order)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_native_byte_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_native_byte_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             with _validate_fileobject_and_memmap(f, filename, mmap_mode) as (\n\u001b[1;32m    737\u001b[0m                 \u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'GaussianNB.pkl'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(model, 'GaussianNB.pkl')\n",
        "print(\"Model saved as GaussianNB.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "hjoOfCXH2nEi",
        "outputId": "b861ba70-883f-43e5-c68c-8e49dfc4d200"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-afdb5dfbe240>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Save the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import joblib\n",
        "\n",
        "# Example: Load your dataset CSV again\n",
        "data = pd.read_csv('Micro-credit-Data-file.csv')\n",
        "\n",
        "# Replace 'features' and 'target' with your actual columns\n",
        "X = data.drop('target_column', axis=1)\n",
        "y = data['target_column']\n",
        "\n",
        "# Split into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save model\n",
        "joblib.dump(model, 'GaussianNB.pkl')\n",
        "print(\"Model saved!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "HxKLpoVG2uxs",
        "outputId": "c4b86920-e011-4c12-fb6a-b6bafb7f7c75"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['target_column'] not found in axis\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-4203139443b1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Replace 'features' and 'target' with your actual columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'target_column'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target_column'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5579\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5580\u001b[0m         \"\"\"\n\u001b[0;32m-> 5581\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   5582\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5583\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4787\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4788\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4829\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4830\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4831\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7069\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7070\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask].tolist()} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7071\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7072\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['target_column'] not found in axis\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "import joblib\n",
        "\n",
        "# Assuming your earlier code has run and you have these:\n",
        "# X_train_scaled, y_train, X_test_scaled, y_test\n",
        "\n",
        "model = GaussianNB()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Save the model for later use\n",
        "joblib.dump(model, 'GaussianNB.pkl')\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "\n",
        "# If you want to load the model later:\n",
        "# loaded_model = joblib.load('GaussianNB.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "kpWMowD522S1",
        "outputId": "f79d0c92-6f20-4785-a710-4b409f72f10b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train_scaled' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-ae1586bc7125>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Save the model for later use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train_scaled' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Load Dataset\n",
        "df = pd.read_csv('Micro-credit-Data-file.csv')  # Adjust path if needed\n",
        "\n",
        "# Preprocessing\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Convert categorical columns\n",
        "cat_cols = df.select_dtypes(include='object').columns\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Features and target\n",
        "X = df.drop('label', axis=1)\n",
        "y = df['label']\n",
        "\n",
        "# Train-test split and scaling\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "0eBPrWgz3QrX"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "import joblib\n",
        "\n",
        "model = GaussianNB()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "joblib.dump(model, 'GaussianNB.pkl')\n",
        "\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "2bYQZ84m3Wfv",
        "outputId": "14c6d3b1-076f-4cd3-c5a5-d7a266fb4e63"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'classification_report' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-f24738128080>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'classification_report' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n"
      ],
      "metadata": {
        "id": "w_skV5ze3aQC"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import classification_report\n",
        "import joblib\n",
        "\n",
        "model = GaussianNB()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "joblib.dump(model, 'GaussianNB.pkl')\n",
        "\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zVM4EsA3kSi",
        "outputId": "3f31ed02-b77d-431c-c7f3-a45f0ba30a23"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.22      0.88      0.35      5232\n",
            "           1       0.97      0.55      0.70     36687\n",
            "\n",
            "    accuracy                           0.59     41919\n",
            "   macro avg       0.59      0.71      0.52     41919\n",
            "weighted avg       0.88      0.59      0.66     41919\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, precision_score, recall_score, log_loss\n",
        "import joblib\n",
        "\n",
        "# Initialize model\n",
        "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "\n",
        "# Fit model on scaled training data\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Predict probabilities for log loss\n",
        "y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Print classification report\n",
        "print(\"XGBClassifier Results:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Print precision, recall, log loss\n",
        "print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "print(\"Log Loss:\", log_loss(y_test, y_pred_proba))\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(model, 'XGBClassifier.pkl')\n",
        "print(\"Model saved as XGBClassifier.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7l2FkOc3mmR",
        "outputId": "fdd1ea71-ea6c-4250-a162-e054bbb1a43a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:36:46] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBClassifier Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.57      0.64      5232\n",
            "           1       0.94      0.97      0.96     36687\n",
            "\n",
            "    accuracy                           0.92     41919\n",
            "   macro avg       0.84      0.77      0.80     41919\n",
            "weighted avg       0.92      0.92      0.92     41919\n",
            "\n",
            "Precision: 0.9401833219196123\n",
            "Recall: 0.9729604492054407\n",
            "Log Loss: 0.18963605712718073\n",
            "Model saved as XGBClassifier.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, log_loss\n",
        "import time\n",
        "\n",
        "results = []\n",
        "\n",
        "# QDA\n",
        "start = time.time()\n",
        "qda = QuadraticDiscriminantAnalysis()\n",
        "qda.fit(X_train_scaled, y_train)\n",
        "y_pred = qda.predict(X_test_scaled)\n",
        "y_prob = qda.predict_proba(X_test_scaled)\n",
        "results.append({\n",
        "    \"Model\": \"QuadraticDiscriminantAnalysis\",\n",
        "    \"Precision\": precision_score(y_test, y_pred),\n",
        "    \"Recall\": recall_score(y_test, y_pred),\n",
        "    \"Log Loss\": log_loss(y_test, y_prob),\n",
        "    \"Time (s)\": time.time() - start\n",
        "})\n",
        "\n",
        "# LDA\n",
        "start = time.time()\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "lda.fit(X_train_scaled, y_train)\n",
        "y_pred = lda.predict(X_test_scaled)\n",
        "y_prob = lda.predict_proba(X_test_scaled)\n",
        "results.append({\n",
        "    \"Model\": \"LinearDiscriminantAnalysis\",\n",
        "    \"Precision\": precision_score(y_test, y_pred),\n",
        "    \"Recall\": recall_score(y_test, y_pred),\n",
        "    \"Log Loss\": log_loss(y_test, y_prob),\n",
        "    \"Time (s)\": time.time() - start\n",
        "})\n",
        "\n",
        "# DummyClassifier (stratified)\n",
        "start = time.time()\n",
        "dummy = DummyClassifier(strategy=\"stratified\")\n",
        "dummy.fit(X_train_scaled, y_train)\n",
        "y_pred = dummy.predict(X_test_scaled)\n",
        "y_prob = dummy.predict_proba(X_test_scaled)\n",
        "results.append({\n",
        "    \"Model\": \"DummyClassifier-stratified\",\n",
        "    \"Precision\": precision_score(y_test, y_pred),\n",
        "    \"Recall\": recall_score(y_test, y_pred),\n",
        "    \"Log Loss\": log_loss(y_test, y_prob),\n",
        "    \"Time (s)\": time.time() - start\n",
        "})\n",
        "\n",
        "# Calibrated Classifier (with RidgeClassifier)\n",
        "start = time.time()\n",
        "ridge = RidgeClassifier()\n",
        "calib = CalibratedClassifierCV(ridge)\n",
        "calib.fit(X_train_scaled, y_train)\n",
        "y_pred = calib.predict(X_test_scaled)\n",
        "y_prob = calib.predict_proba(X_test_scaled)\n",
        "results.append({\n",
        "    \"Model\": \"Calibrated-RidgeClassifier\",\n",
        "    \"Precision\": precision_score(y_test, y_pred),\n",
        "    \"Recall\": recall_score(y_test, y_pred),\n",
        "    \"Log Loss\": log_loss(y_test, y_prob),\n",
        "    \"Time (s)\": time.time() - start\n",
        "})\n",
        "\n",
        "# GaussianNB (Binarized)\n",
        "from sklearn.preprocessing import Binarizer\n",
        "start = time.time()\n",
        "binarizer = Binarizer().fit(X_train_scaled)\n",
        "X_train_bin = binarizer.transform(X_train_scaled)\n",
        "X_test_bin = binarizer.transform(X_test_scaled)\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train_bin, y_train)\n",
        "y_pred = gnb.predict(X_test_bin)\n",
        "y_prob = gnb.predict_proba(X_test_bin)\n",
        "results.append({\n",
        "    \"Model\": \"GaussianNB-Binarized\",\n",
        "    \"Precision\": precision_score(y_test, y_pred),\n",
        "    \"Recall\": recall_score(y_test, y_pred),\n",
        "    \"Log Loss\": log_loss(y_test, y_prob),\n",
        "    \"Time (s)\": time.time() - start\n",
        "})\n",
        "\n",
        "# Create DataFrame of new results\n",
        "import pandas as pd\n",
        "new_models_df = pd.DataFrame(results)\n",
        "print(new_models_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REuUl3Av390w",
        "outputId": "b13154bd-12dd-44a3-89ee-b0fcb8577349"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                           Model  Precision    Recall  Log Loss  Time (s)\n",
            "0  QuadraticDiscriminantAnalysis   0.977794  0.446480  5.611335  1.330966\n",
            "1     LinearDiscriminantAnalysis   0.875418  0.999428  0.312908  1.819527\n",
            "2     DummyClassifier-stratified   0.875521  0.876141  7.913112  0.055706\n",
            "3     Calibrated-RidgeClassifier   0.877495  0.993404  0.311834  3.442340\n",
            "4           GaussianNB-Binarized   0.961228  0.669011  2.738266  0.401710\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = pd.concat([existing_df, new_models_df], ignore_index=True)\n",
        "final_df.to_csv('updated_models_metrics.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "anjiQTJr4hGW",
        "outputId": "ef115a07-c089-4683-9164-4ba5ced1198c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'existing_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-e18d1a05d2ee>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexisting_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_models_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'updated_models_metrics.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'existing_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the existing model results CSV\n",
        "existing_df = pd.read_csv('model_comparison_results.csv')  # Replace with your actual filename if different\n",
        "\n",
        "# Now concatenate with the new models\n",
        "final_df = pd.concat([existing_df, new_models_df], ignore_index=True)\n",
        "\n",
        "# Save the updated list of models\n",
        "final_df.to_csv('updated_models_metrics.csv', index=False)\n",
        "\n",
        "print(\"✅ Model list updated and saved as 'updated_models_metrics.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5ZtYaam4nWE",
        "outputId": "98a1b082-c5b5-4b94-ec61-5b4e783abcd7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model list updated and saved as 'updated_models_metrics.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.metrics import precision_score, recall_score, log_loss, classification_report\n",
        "import time\n",
        "\n",
        "# Start timing\n",
        "start = time.time()\n",
        "\n",
        "# Initialize and train the model\n",
        "qda_model = QuadraticDiscriminantAnalysis()\n",
        "qda_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = qda_model.predict(X_test_scaled)\n",
        "y_proba = qda_model.predict_proba(X_test_scaled)\n",
        "\n",
        "# Evaluate\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "loss = log_loss(y_test, y_proba)\n",
        "duration = time.time() - start\n",
        "\n",
        "print(\"QDA Results:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"Log Loss:\", loss)\n",
        "print(\"Time Taken:\", duration)\n",
        "\n",
        "# Add to DataFrame if you're collecting model results\n",
        "new_model_result = pd.DataFrame([{\n",
        "    'Model': 'QuadraticDiscriminantAnalysis',\n",
        "    'Precision': precision,\n",
        "    'Recall': recall,\n",
        "    'Log Loss': loss,\n",
        "    'Time (s)': duration\n",
        "}])\n",
        "\n",
        "# If you already have a DataFrame of results (like existing_df or final_df):\n",
        "# final_df = pd.concat([final_df, new_model_result], ignore_index=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HEBkiG64v9_",
        "outputId": "806a2ee5-288b-41da-ca5e-2df60930770e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QDA Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.19      0.93      0.32      5232\n",
            "           1       0.98      0.45      0.61     36687\n",
            "\n",
            "    accuracy                           0.51     41919\n",
            "   macro avg       0.59      0.69      0.47     41919\n",
            "weighted avg       0.88      0.51      0.58     41919\n",
            "\n",
            "Precision: 0.9777936962750716\n",
            "Recall: 0.44647967945048656\n",
            "Log Loss: 5.611335371070336\n",
            "Time Taken: 0.9648327827453613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load existing results CSV\n",
        "final_df = pd.read_csv('updated_models_metrics.csv')  # Adjust the filename if different\n"
      ],
      "metadata": {
        "id": "ZBnaX-c45Fif"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace these with actual values from your QDA model run\n",
        "qda_result = pd.DataFrame([{\n",
        "    'Model': 'QuadraticDiscriminantAnalysis',\n",
        "    'Precision': precision,  # from your QDA evaluation\n",
        "    'Recall': recall,\n",
        "    'Log Loss': loss,\n",
        "    'Time (s)': duration\n",
        "}])\n",
        "\n",
        "# Concatenate and save\n",
        "final_df = pd.concat([final_df, qda_result], ignore_index=True)\n",
        "final_df.to_csv('updated_models_metrics.csv', index=False)\n"
      ],
      "metadata": {
        "id": "-oHZe42E5NUo"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_df.tail())  # Shows the last few rows including the new entry\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF7aD3_e5QJE",
        "outputId": "049c753b-d130-4774-b5b7-1cfee5204f66"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            Model  Precision    Recall  Log Loss  Time (s)\n",
            "40     LinearDiscriminantAnalysis   0.875418  0.999428  0.312908  1.819527\n",
            "41     DummyClassifier-stratified   0.875521  0.876141  7.913112  0.055706\n",
            "42     Calibrated-RidgeClassifier   0.877495  0.993404  0.311834  3.442340\n",
            "43           GaussianNB-Binarized   0.961228  0.669011  2.738266  0.401710\n",
            "44  QuadraticDiscriminantAnalysis   0.977794  0.446480  5.611335  0.964833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Aa5iY5ud5U7g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}